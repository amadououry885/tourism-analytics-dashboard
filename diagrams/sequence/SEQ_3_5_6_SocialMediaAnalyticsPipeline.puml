@startuml Social Media Analytics Pipeline Sequence

title Figure 3.13: Social Media Analytics Pipeline Sequence

skinparam backgroundColor #FEFEFE
skinparam sequenceArrowThickness 2
skinparam roundcorner 10

participant "Celery Beat\n(Scheduler)" as SCHED #FFECB3
participant "Celery Worker\n(Background Task)" as WORKER #E8F5E9
participant "Social Media APIs\n(Instagram/Twitter/Facebook)" as SOCIAL #E3F2FD
participant "NLP Service\n(Sentiment Analysis)" as NLP #F3E5F5
participant "Backend\n(Django)" as BE #E8F5E9
database "Database\n(PostgreSQL)" as DB #FFF3E0
participant "Cache\n(Redis)" as CACHE #FFCDD2

== Scheduled Task Trigger ==

note over SCHED: Celery Beat Schedule:\ncrontab(minute=0, hour='*/2')\nRuns every 2 hours

SCHED -> WORKER: Trigger task:\ncollect_and_process_social_posts()

activate WORKER

== Step 1: Fetch Social Media Posts ==

WORKER -> DB: Get list of tourism places\nSELECT name, city FROM places
DB --> WORKER: Places list for search keywords

loop For each social platform
    
    WORKER -> WORKER: Build search queries:\n- Place names\n- City hashtags\n- Tourism keywords
    
    == Instagram API ==
    WORKER -> SOCIAL: GET Instagram posts\n#AlorSetar #KedahTourism #Langkawi
    SOCIAL --> WORKER: Instagram posts JSON\n[{id, content, likes, comments, ...}]
    
    == Twitter/X API ==
    WORKER -> SOCIAL: GET Tweets\nquery: "Alor Setar tourism OR Langkawi beach"
    SOCIAL --> WORKER: Tweets JSON\n[{id, text, retweets, likes, ...}]
    
    == Facebook API ==
    WORKER -> SOCIAL: GET Facebook posts\nfrom tourism pages
    SOCIAL --> WORKER: Facebook posts JSON\n[{id, message, reactions, shares, ...}]
    
end

WORKER -> WORKER: Normalize data format:\n{platform, post_id, content,\nlikes, comments, shares, url, created_at}

== Step 2: Filter Tourism-Related Content ==

loop For each fetched post
    WORKER -> WORKER: Check tourism relevance:\n- Contains place keywords?\n- Has tourism hashtags?\n- Mentions Kedah locations?
    
    alt Not Tourism Related
        WORKER -> WORKER: Skip post (is_tourism=False)
    else Tourism Related
        WORKER -> WORKER: Mark for processing\n(is_tourism=True)
    end
end

WORKER -> WORKER: Filtered posts ready\nfor sentiment analysis

== Step 3: Sentiment Analysis (NLP) ==

loop For each tourism post
    WORKER -> NLP: Analyze sentiment:\n{text: "Beautiful sunset at Langkawi!\nAmazing beach view ðŸŒ…"}
    
    NLP -> NLP: Process text:\n1. Tokenization\n2. Remove stopwords\n3. Feature extraction\n4. Classification model
    
    NLP --> WORKER: Sentiment result:\n{sentiment: "positive",\nsentiment_score: 0.85,\nconfidence: 92.5,\nkeywords: ["beautiful", "amazing"]}
end

== Step 4: Link Posts to Places ==

loop For each analyzed post
    WORKER -> WORKER: Extract location mentions\nfrom post content
    
    WORKER -> DB: Find matching place:\nSELECT id FROM places\nWHERE name ILIKE '%{mention}%'\nOR city ILIKE '%{mention}%'
    DB --> WORKER: Matching place_id (or null)
    
    WORKER -> WORKER: Associate post with place
end

== Step 5: Store in Database ==

WORKER -> DB: Check for duplicates:\nSELECT id FROM social_posts\nWHERE platform={platform}\nAND post_id={post_id}
DB --> WORKER: Existing post or null

alt Post Already Exists
    WORKER -> DB: UPDATE social_posts\nSET likes={new_likes},\ncomments={new_comments}\nWHERE id={existing_id}
    DB --> WORKER: Engagement updated
else New Post
    WORKER -> DB: INSERT INTO social_posts\n(platform, post_id, content,\nsentiment, sentiment_score, confidence,\nlikes, comments, shares,\nplace_id, created_at)
    DB --> WORKER: Post stored (ID)
end

== Step 6: Update Analytics Cache ==

WORKER -> WORKER: Calculate aggregations:\n- Sentiment distribution\n- Platform breakdown\n- Trending places

WORKER -> CACHE: SET sentiment_summary:{city}\n{positive: X, negative: Y, neutral: Z}\nTTL: 7200s
CACHE --> WORKER: Cached

WORKER -> CACHE: SET social_platforms_stats\n{instagram: N, twitter: M, facebook: K}\nTTL: 7200s
CACHE --> WORKER: Cached

WORKER -> CACHE: SET trending_places\n[{place_id, mention_count, sentiment_avg}]\nTTL: 7200s
CACHE --> WORKER: Cached

deactivate WORKER

== Step 7: Dashboard Retrieval ==

actor "Admin" as A #FFE0B2

A -> BE: GET /api/analytics/sentiment/summary/
BE -> CACHE: GET sentiment_summary:city=all
CACHE --> BE: Cached data (if exists)

alt Cache Hit
    BE --> A: Return cached sentiment data
else Cache Miss
    BE -> DB: Aggregate from social_posts
    DB --> BE: Fresh sentiment data
    BE -> CACHE: Cache result
    BE --> A: Return sentiment data
end

A -> BE: GET /api/analytics/social-platforms/
BE -> CACHE: GET social_platforms_stats
CACHE --> BE: Platform distribution
BE --> A: {instagram: 45%, twitter: 30%, facebook: 25%}

A -> BE: GET /api/analytics/places/trending/
BE -> CACHE: GET trending_places
CACHE --> BE: Trending places list
BE --> A: [{name: "Langkawi", mentions: 150, sentiment: 0.78}, ...]

== Error Handling ==

note over WORKER, SOCIAL
If API rate limit exceeded:
- Log warning
- Retry with exponential backoff
- Continue with other platforms
end note

note over WORKER, NLP
If NLP service unavailable:
- Store post with sentiment='unknown'
- Queue for later processing
end note

@enduml
